{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# RNN\n",
    "Implementation of a Elman RNN (the same as in PyTorch) and Jordan networks.\n",
    "\n",
    "The goal is to train them on the same data and comapre the results.\n",
    "\n",
    "[Paper1 - Elman](https://doi.org/10.1207/s15516709cog1402_1)\n",
    "\n",
    "[Paper2 - Jordan](https://www.sciencedirect.com/science/article/abs/pii/S0166411597801112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.init as init  # Add this import to access the init module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 512])\n",
      "torch.Size([64, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "class ElmanRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Elman Recurrent Neural Network (ELM-RNN) is a type of recurrent neural network that includes a context memory unit. This class provides a complete implementation of the Elman RNN, including initialization, forward pass, and methods to reset the context units.\n",
    "\n",
    "    Parameters:\n",
    "    sequence_dim (int): Dimensionality of the input sequence.\n",
    "    hidden_size (int): Number of units in the hidden layer.\n",
    "\n",
    "    Attributes:\n",
    "    inputs_weight (torch.Tensor): Weight matrix for input connection.\n",
    "    context_weight (torch.Tensor): Weight matrix for context connection.\n",
    "    output_weight (torch.Tensor): Weight matrix for output connection.\n",
    "    hidden_bias (torch.Tensor): Bias vector for the hidden layer.\n",
    "    input_bias (torch.Tensor): Bias vector for the input layer.\n",
    "    output_bias (torch.Tensor): Bias vector for the output layer.\n",
    "    context_units (torch.Tensor): Tensor to store context units, used only within a single sequence.\n",
    "\n",
    "    Methods:\n",
    "    reset_context(batch_size, hidden_size): Resets the context units before processing the next batch.\n",
    "    forward(input_units): Performs the forward pass of the Elman RNN on the input sequence. Returns the output tensor.\n",
    "    \"\"\"    \n",
    "    def __init__(self, sequence_dim, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        self.inputs_weight = nn.Parameter(torch.empty(sequence_dim,\n",
    "                                                      hidden_size),\n",
    "                                           requires_grad=True)\n",
    "        self.context_weight = nn.Parameter(torch.empty(hidden_size,\n",
    "                                                       hidden_size),\n",
    "                                           requires_grad=True)\n",
    "        self.output_weight = nn.Parameter(torch.empty(hidden_size,\n",
    "                                                1),\n",
    "                                    requires_grad=True)\n",
    "\n",
    "        self.hidden_bias = nn.Parameter(torch.empty(hidden_size), requires_grad=True)\n",
    "        self.input_bias = nn.Parameter(torch.empty(hidden_size), requires_grad=True)\n",
    "        self.output_bias = nn.Parameter(torch.empty(1), requires_grad=True)\n",
    "\n",
    "        self.context_units = None\n",
    "\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Initialize weights with Xavier (Glorot) initialization\n",
    "        init.xavier_uniform_(self.inputs_weight)\n",
    "        init.xavier_uniform_(self.context_weight)\n",
    "        init.xavier_uniform_(self.output_weight)\n",
    "\n",
    "        init.zeros_(self.hidden_bias)\n",
    "        init.zeros_(self.input_bias)\n",
    "        init.zeros_(self.output_bias)\n",
    "\n",
    "    def reset_context(self, batch_size, hidden_size):\n",
    "        \"\"\"Remember reset context after each sample from batch.\n",
    "        The idea is that the context is valid only for given sequence.\n",
    "        \"\"\"\n",
    "        self.context_units = torch.zeros(batch_size, hidden_size, requires_grad=False)\n",
    "        \n",
    "    def forward(self, input_units):\n",
    "        batch_size, _, sequence_length = input_units.size()\n",
    "        hidden_size = self.hidden_bias.size(0)\n",
    "        \n",
    "        # Reset context units for the new batch\n",
    "        self.reset_context(batch_size, hidden_size)\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for t in range(sequence_length):\n",
    "            # Extract the input at time step t\n",
    "            x_t = input_units[:, :, t] # Shape: (batch_size, sequence_dim)\n",
    "            \n",
    "            h1 = x_t@self.inputs_weight + self.input_bias\n",
    "            h2 = self.context_units@self.context_weight  + self.hidden_bias # Shape: (batch_size, hidden_size)\n",
    "            hidden = self.activation(h1 + h2)\n",
    "            self.context_units = hidden\n",
    "            output.append(hidden)\n",
    "            \n",
    "        hidden_output = torch.stack(output, dim=2)\n",
    "        output = nn.functional.sigmoid(torch.transpose(hidden_output, 1,2)@self.output_weight + self.output_bias)\n",
    "        return torch.transpose(output,1,2)\n",
    "            \n",
    "batch_size = 64\n",
    "sequence_length = 512\n",
    "sequence_dim = 1\n",
    "hidden_size = 10\n",
    " \n",
    "layer = ElmanRNN(sequence_dim, hidden_size)\n",
    "test_input = torch.randn(batch_size, sequence_dim, sequence_length)\n",
    "print(test_input.shape)\n",
    "output = layer(test_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape: torch.Size([64, 1, 15])\n",
      "Output Data Shape: torch.Size([64, 1, 15])\n",
      "Sample Input Data: tensor([[1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.]])\n",
      "Sample Output Data: tensor([[0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "def generate_xor_sequence_data(batch_size, sequence_length):\n",
    "    # Each sequence will have a structure of (input1, input2, output)\n",
    "    seq_dim = 1  # Single dimensional input\n",
    "\n",
    "    # Initialize the input and output data tensors\n",
    "    input_data = torch.zeros(batch_size, sequence_length, seq_dim)\n",
    "    output_data = torch.zeros(batch_size, sequence_length, seq_dim)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sequence = []\n",
    "        output_sequence = []\n",
    "\n",
    "        for _ in range(sequence_length // 3):  # Divide by 3 because each (input1, input2, output) is 3 units\n",
    "            input1 = torch.randint(0, 2, (1,))\n",
    "            input2 = torch.randint(0, 2, (1,))\n",
    "            xor_output = input1 ^ input2\n",
    "\n",
    "            sequence.extend([input1, input2, xor_output])  # Add inputs and output to the sequence\n",
    "\n",
    "        for t in range(1, sequence_length-1):\n",
    "            output_data[i][t] = sequence[t-1] ^ sequence[t]\n",
    "\n",
    "        # Store the input sequence\n",
    "        input_data[i] = torch.tensor(sequence).view(-1, 1)  # Flatten to make it 2D\n",
    "\n",
    "\n",
    "    return input_data.view(batch_size, 1, sequence_length), output_data.view(batch_size, 1, sequence_length)\n",
    "\n",
    "# Example usage\n",
    "batch_size = 64\n",
    "sequence_length = 5*3  # This should be a multiple of 3 for the (input1, input2, output) structure\n",
    "\n",
    "input_data, output_data = generate_xor_sequence_data(batch_size, sequence_length)\n",
    "print(\"Input Data Shape:\", input_data.shape)\n",
    "print(\"Output Data Shape:\", output_data.shape)\n",
    "print(\"Sample Input Data:\", input_data[0])\n",
    "print(\"Sample Output Data:\", output_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000, Loss: 0.007366681005805731: 100%|██████████| 1000/1000 [00:05<00:00, 181.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000  # Number of epochs\n",
    "\n",
    "#  model\n",
    "layer = ElmanRNN(sequence_dim=1, hidden_size=16)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(layer.parameters(), lr=0.1)\n",
    "\n",
    "# Generate XOR sequence data (make sure you have the generate_xor_sequence_data function)\n",
    "batch_size = 64\n",
    "sequence_length = 90  # This should be a multiple of 3 for the (input1, input2, output) structure\n",
    "input_data, target_data = generate_xor_sequence_data(batch_size, sequence_length)\n",
    "\n",
    "p_bar = tqdm(range(num_epochs))\n",
    "for epoch in p_bar:\n",
    "    optimizer.zero_grad()\n",
    "    output = layer(input_data)\n",
    "    loss = loss_function(output, target_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    p_bar.set_description(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.]]])\n",
      "tensor([[[0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([[[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]]])\n",
    "    test_output = layer(test_input)\n",
    "    \n",
    "    \n",
    "def apply_threshold(x, threshold):\n",
    "    # Apply threshold: 1 if element >= threshold, else 0\n",
    "    return (x >= threshold).float()\n",
    "\n",
    "print(test_input)\n",
    "print(apply_threshold(test_output, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1417,  4.0154,  4.4737, -5.0839,  6.1151, -4.9540, -0.7877,  4.8677,\n",
       "         -0.4399, -3.3194,  0.4632, -1.3784,  0.9087,  5.5866, -3.4849,  1.0458]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.inputs_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.4613, -1.7699,  0.4481,  0.6518,  0.9535,  0.2729, -0.9101, -0.4545,\n",
       "        -1.0467,  1.5609,  1.0792,  1.2492,  1.3319, -1.3297, -0.1763, -1.3552],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.input_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1729],\n",
       "        [ 1.1632],\n",
       "        [-1.2871],\n",
       "        [ 4.1294],\n",
       "        [-2.0377],\n",
       "        [-2.0161],\n",
       "        [ 1.4098],\n",
       "        [ 2.0389],\n",
       "        [ 0.2062],\n",
       "        [ 1.4368],\n",
       "        [-0.6120],\n",
       "        [-0.9037],\n",
       "        [-0.5836],\n",
       "        [ 2.3551],\n",
       "        [-0.5792],\n",
       "        [ 0.5402]], requires_grad=True)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.output_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
